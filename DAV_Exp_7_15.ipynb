{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanD172/DAV-LAB/blob/main/DAV_Exp_7_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAVs1ls4UhvU"
      },
      "source": [
        "**Aim:**<br>\n",
        "Getting introduced to visualization libraries in Python and R. <br>\n",
        "\n",
        "\n",
        "**Lab Objectives:**<br> To effectively use libraries for data analytics.<br>\n",
        "\n",
        "**Lab Outcomes:**<br>\n",
        "Implement visualization techniques to given data sets using R\n",
        "Implement visualization techniques to given data sets using Python\n",
        "\n",
        "\n",
        "\n",
        "**Lab Objectives:**<br>\n",
        "To effectively use libraries for data analytics.<br>\n",
        "Identify 5 Python and R Libraries for Data Visualization.<br>\n",
        "Prepare a brief summary about their features and applications. <br>\n",
        "Perform simple experiments on 2 Libraries each for Python & R\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e64gvyx4WBbG"
      },
      "source": [
        "# **Text Analytics in Python**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hM27nyWfuB6",
        "outputId": "743c3374-1a92-4e0e-a2b2-3255504dc17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1wvAaU8f6J7",
        "outputId": "5bfebfe0-ec72-4d2b-9ecb-b80614740fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXKbAYZpUjTv",
        "outputId": "86c832de-06a0-4491-8d07-b98fe5eac674"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Download necessary resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0D3InJ0gOg3"
      },
      "outputs": [],
      "source": [
        "# Function to scrape text from a website\n",
        "def scrape_text(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # Extract text from paragraphs\n",
        "    paragraphs = soup.find_all('p')\n",
        "    text = ' '.join([para.get_text() for para in paragraphs])\n",
        "    return text\n",
        "\n",
        "# URL of the Wikipedia article to scrape\n",
        "url = 'https://en.wikipedia.org/wiki/Natural_language_processing'\n",
        "text = scrape_text(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNP5NyEQf5I3",
        "outputId": "01739e5f-e8b4-4f58-ab6e-34592c8e0527"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequency Distribution:\n",
            "[(',', 74), ('the', 61), ('of', 55), ('.', 44), ('and', 31), ('[', 29), (']', 29), ('in', 26), ('language', 22), ('to', 19)]\n"
          ]
        }
      ],
      "source": [
        "# Tokenization (Sentence & Word)\n",
        "sentences = sent_tokenize(text)\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Frequency Distribution\n",
        "fdist = FreqDist(words)\n",
        "print(\"Frequency Distribution:\")\n",
        "print(fdist.most_common(10))\n",
        "\n",
        "# Remove stopwords & punctuations\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "\n",
        "# Lexicon Normalization (Stemming, Lemmatization)\n",
        "porter = PorterStemmer()\n",
        "stemmed_words = [porter.stem(word) for word in filtered_words]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "# Part of Speech tagging\n",
        "pos_tags = pos_tag(filtered_words)\n",
        "\n",
        "# Named Entity Recognition\n",
        "named_entities = ne_chunk(pos_tags)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix4Tmi70UjWy",
        "outputId": "e50c2b31-c2aa-48ca-8b0a-7821f7d0d9ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed Text:\n",
            "Sentences: 44\n",
            "Words before processing: 1363\n",
            "Words after processing: 686\n",
            "Stemmed Words: ['natur', 'languag', 'process', 'nlp', 'interdisciplinari', 'subfield', 'comput', 'scienc', 'linguist', 'primarili']\n",
            "Lemmatized Words: ['natural', 'language', 'processing', 'nlp', 'interdisciplinary', 'subfield', 'computer', 'science', 'linguistics', 'primarily']\n",
            "POS Tags: [('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('nlp', 'JJ'), ('interdisciplinary', 'JJ'), ('subfield', 'NN'), ('computer', 'NN'), ('science', 'NN'), ('linguistics', 'NNS'), ('primarily', 'RB')]\n",
            "Named Entities: [('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('nlp', 'JJ'), ('interdisciplinary', 'JJ'), ('subfield', 'NN'), ('computer', 'NN'), ('science', 'NN'), ('linguistics', 'NNS'), ('primarily', 'RB')]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nProcessed Text:\")\n",
        "print(\"Sentences:\", len(sentences))\n",
        "print(\"Words before processing:\", len(words))\n",
        "print(\"Words after processing:\", len(filtered_words))\n",
        "print(\"Stemmed Words:\", stemmed_words[:10])\n",
        "print(\"Lemmatized Words:\", lemmatized_words[:10])\n",
        "print(\"POS Tags:\", pos_tags[:10])\n",
        "print(\"Named Entities:\", named_entities[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJbhvsquUiCy"
      },
      "source": [
        "# **Text Analytics in R**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tau80TWk5Ah",
        "outputId": "95b4f82e-5d8a-41ba-f1b5-0284a12b9ec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘Rcpp’, ‘SnowballC’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages('tokenizers')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsB40zKPnd5k",
        "outputId": "f3c835c3-70d1-4131-e337-1c850054b705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependencies ‘NLP’, ‘slam’, ‘BH’\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "install.packages('tm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('rvest')"
      ],
      "metadata": {
        "id": "q7tUVuIdwmaL",
        "outputId": "97705d63-768f-456f-b300-c0b2733e6adc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(tm)\n",
        "library(rvest)\n",
        "library(NLP)\n",
        "library(tokenizers)\n",
        "library(SnowballC)"
      ],
      "metadata": {
        "id": "bfGtzWcjwIgZ",
        "outputId": "24724ba7-d44f-4cc0-f200-b8043634b934",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: NLP\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sF7pfOclfPxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268f7764-1c67-481a-e558-582127236948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Tokens: He raced to the grocery store. He went inside but realized he forgot his wallet. He raced back home to grab it. Once he found it, he raced to the car again and drove back to the grocery store. \n",
            "Word Tokens: he raced to the grocery store he went inside but realized he forgot his wallet he raced back home to grab it once he found it he raced to the car again and drove back to the grocery store \n"
          ]
        }
      ],
      "source": [
        "text <- \"He raced to the grocery store. He went inside but realized he forgot his wallet. He raced back home to grab it. Once he found it, he raced to the car again and drove back to the grocery store.\"\n",
        "# Tokenisation\n",
        "nsent_tokens <- unlist(tokenize_sentences(text))\n",
        "word_tokens <- unlist(tokenize_words(text))\n",
        "cat(\"Sentence Tokens:\", sent_tokens, \"\\n\")\n",
        "cat(\"Word Tokens:\", word_tokens, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency Distribution\n",
        "fdist <- table(unlist(word_tokens))\n",
        "print(head(sort(fdist, decreasing = TRUE), 2))"
      ],
      "metadata": {
        "id": "iorvqdzYx2hy",
        "outputId": "675561f3-fb12-4ccc-f591-4f95d26317e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "he to \n",
            " 6  4 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords and punctuations\n",
        "stop_words <- stopwords(\"en\")\n",
        "filtered_tokens <- word_tokens[!(word_tokens %in% stop_words) & grepl(\"[a-zA-Z]\", word_tokens)]\n",
        "cat(\"Filtered Tokens (without stopwords and punctuations):\", filtered_tokens, \"\\n\")"
      ],
      "metadata": {
        "id": "4rgzwpZFxnuA",
        "outputId": "64d21397-ef39-43a2-ae63-439a736bacf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Tokens (without stopwords and punctuations): raced grocery store went inside realized forgot wallet raced back home grab found raced car drove back grocery store \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "stemmed_tokens <- wordStem(filtered_tokens, language = \"en\")\n",
        "cat(\"Stemmed Tokens:\", stemmed_tokens, \"\\n\")"
      ],
      "metadata": {
        "id": "Tv_TfbSXxnx8",
        "outputId": "91e51bf0-56d0-4bc2-deab-921c0d3a629a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed Tokens: race groceri store went insid realiz forgot wallet race back home grab found race car drove back groceri store \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatized_text <- tolower(text)\n",
        "lemmatized_text <- wordStem(lemmatized_text, language = \"en\")\n",
        "\n",
        "cat(\"Lemmatized Text:\", lemmatized_text, \"\\n\")"
      ],
      "metadata": {
        "id": "EnJSMSlLxn1O",
        "outputId": "45955c6e-dc30-4137-a398-c5a94ce446dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized Text: he raced to the grocery store. he went inside but realized he forgot his wallet. he raced back home to grab it. once he found it, he raced to the car again and drove back to the grocery store. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Web Scraping\n",
        "url <- 'http://quotes.toscrape.com/'\n",
        "web_page <- read_html(url)\n",
        "web_text <- html_text(web_page)\n",
        "cat(\"Scraped Data from the Website:\\n\", web_text)"
      ],
      "metadata": {
        "id": "2m7TZRrqyE_C",
        "outputId": "c53c73e7-023d-454c-af10-250abda27633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Data from the Website:\n",
            " Quotes to Scrape\n",
            "    \n",
            "        \n",
            "            \n",
            "                \n",
            "                    Quotes to Scrape\n",
            "                \n",
            "            \n",
            "            \n",
            "                \n",
            "                \n",
            "                    Login\n",
            "                \n",
            "                \n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "\n",
            "    \n",
            "\n",
            "    \n",
            "        “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            change\n",
            "            \n",
            "            deep-thoughts\n",
            "            \n",
            "            thinking\n",
            "            \n",
            "            world\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
            "        by J.K. Rowling\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            abilities\n",
            "            \n",
            "            choices\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            inspirational\n",
            "            \n",
            "            life\n",
            "            \n",
            "            live\n",
            "            \n",
            "            miracle\n",
            "            \n",
            "            miracles\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
            "        by Jane Austen\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            aliteracy\n",
            "            \n",
            "            books\n",
            "            \n",
            "            classic\n",
            "            \n",
            "            humor\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
            "        by Marilyn Monroe\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            be-yourself\n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “Try not to become a man of success. Rather become a man of value.”\n",
            "        by Albert Einstein\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            adulthood\n",
            "            \n",
            "            success\n",
            "            \n",
            "            value\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “It is better to be hated for what you are than to be loved for what you are not.”\n",
            "        by André Gide\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            life\n",
            "            \n",
            "            love\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “I have not failed. I've just found 10,000 ways that won't work.”\n",
            "        by Thomas A. Edison\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            edison\n",
            "            \n",
            "            failure\n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "            paraphrased\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
            "        by Eleanor Roosevelt\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            misattributed-eleanor-roosevelt\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "        “A day without sunshine is like, you know, night.”\n",
            "        by Steve Martin\n",
            "        (about)\n",
            "        \n",
            "        \n",
            "            Tags:\n",
            "            humor\n",
            "            \n",
            "            obvious\n",
            "            \n",
            "            simile\n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "    \n",
            "                Next →\n",
            "            \n",
            "            \n",
            "        \n",
            "    \n",
            "        \n",
            "            Top Ten tags\n",
            "            \n",
            "            \n",
            "            love\n",
            "            \n",
            "            \n",
            "            \n",
            "            inspirational\n",
            "            \n",
            "            \n",
            "            \n",
            "            life\n",
            "            \n",
            "            \n",
            "            \n",
            "            humor\n",
            "            \n",
            "            \n",
            "            \n",
            "            books\n",
            "            \n",
            "            \n",
            "            \n",
            "            reading\n",
            "            \n",
            "            \n",
            "            \n",
            "            friendship\n",
            "            \n",
            "            \n",
            "            \n",
            "            friends\n",
            "            \n",
            "            \n",
            "            \n",
            "            truth\n",
            "            \n",
            "            \n",
            "            \n",
            "            simile\n",
            "            \n",
            "            \n",
            "        \n",
            "    \n",
            "\n",
            "\n",
            "    \n",
            "    \n",
            "            \n",
            "                Quotes by: GoodReads.com\n",
            "            \n",
            "            \n",
            "                Made with ❤ by Zyte\n",
            "            \n",
            "        \n",
            "    "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhYjm4o/gh63Y17IwCmBw1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}